// This is a tutorial script demonstrating the Reflex programming language.
// 
// For detailed instructions and further information see 
// https://incapture.atlassian.net/wiki/display/PDT/Rapture+Getting+Started%3A+REFLEX//
//
// Reflex and Rapture are trademarks of Incapture Technologies LLC

SERIES_AUTHORITY="datacapture";
BLOB_AUTHORITY="tutorialBlob";
DOC_AUTHORITY="tutorialDoc";

BLOB_URI="blob://"+BLOB_AUTHORITY;
DOC_URI="document://"+DOC_AUTHORITY;
SERIES_URI="series://"+SERIES_AUTHORITY;

CSV_FILE = ENV.RAPTURE_TUTORIAL_CSV;
if (CSV_FILE == null) do
  CSV_FILE = "introDataInbound.csv";
  println("No CSV specified. Defaulting to "+CSV_FILE);
end

// **********************
// Create repos if needed
// **********************

if (!#blob.blobRepoExists(BLOB_URI)) do
     #blob.createBlobRepo(BLOB_URI, "BLOB {} USING MONGODB {prefix=\""+BLOB_AUTHORITY+"\" }", "REP {} USING MONGODB { prefix=\""+BLOB_AUTHORITY+"\"}");
end
if (!#doc.docRepoExists(DOC_URI)) do
    #doc.createDocRepo(DOC_URI, "REP {} USING MONGODB {prefix=\""+DOC_AUTHORITY+"\"}");
end
if (!#series.seriesRepoExists(SERIES_URI)) do
    #series.createSeriesRepo(SERIES_URI, "SREP {} USING MONGODB {prefix=\""+SERIES_AUTHORITY+"\"}");
end

// **********************
// If the data blob does not exist then attempt to load it.
// Note that the REPL window cannot access the local file system.
// This will only work when invoked using RaptureRunner. 
// **********************

rawCsvUri = BLOB_URI+"/"+CSV_FILE;

if (!#blob.blobExists(rawCsvUri)) do
  println("Reading CSV from file " + CSV_FILE);
  file(CSV_FILE, "CSV") --> rawCsvUri;
  println("CSV uploaded to "+ rawCsvUri);
else do
  println("Data has already been uploaded to the BLOB repository.");
end

println("\nDone\n");

// **********************
// Get data from the blob using the pull operation
// **********************

println("Retrieving raw CSV content from " + rawCsvUri);

// Pull data from the uploaded Blob.
// Rapture keeps track of the types of blobs.
// If the type is defined as CSV then the Pull operation will automatically break it into its component values.
data <-- rawCsvUri;
if data == null do
  println("Nothing found at " + rawCsvUri + ". Please run step 'upload' to add the CSV to Rapture.");
  // Reflex doesn't have an exit operation but assert(false) is the nearest thing.
  assert(false);
end

// **********************
// Or we can get data from the blob using the file read operation and splitting it manually
// **********************

data = [];
for datum in file(rawCsvUri) do
  if datum == null do
    println("Nothing found at " + rawCsvUri + ". Please run step 'upload' to add the CSV to Rapture.");
    // Reflex doesn't have an exit operation but assert(false) is the nearest thing.
    assert(false);
   end
   data.add(split(datum, ",", true));
end

// **********************
// Process the data list.
// **********************

// Process the data. Strip out the header lines.
// Remove hyphens from the date field.
// Treat the last column as a Number

headers = data[0];
noheaders = data.subList(1, data.size());
for datum in noheaders do
    siz = datum.size();
    if (siz >= 2) do
      key = datum[siz -2];
      datum[siz -2] = replace(key,"-","");
      datum[siz -1] = cast(datum[siz -1], 'number');
  end
end

// **********************
// Converting the data to a Document using the Push and Pull operations
// **********************

// Write the CSV as a Document. In Rapture a Document must be a JSON formatted Map.
// Since the data is in a List of Lists it will need to be converted to a Map.
// Pushing the data to the Document repository will automatically convert the data
// to a nested Map of Maps - every unique entry in the first column will become a Key
// and the remaining columns will become values

noheaders --> DOC_URI+"/introDataTranslated";

// When the data is pulled from a Document it is stored as a Map.

introDataTranslated <-- DOC_URI+"/introDataTranslated";

// The data can be referenced via the column values, thus: 
//	introDataTranslated.HIST.Provider_1a.USGG2YR_Index_Dummy.DAILY.LOW


// **********************
// Output the processed data as a Document by creating a map and using the doc.putDoc operation
// **********************

// For the tutorial we have defined a common data format between all the languages 
// Write the data as a map of maps using Provider, SeriesType, Frequency and IndexID as keys.");

indexMap = { };
dataMap = {};
firstEntry = noheaders[0];
for k in [ 0,1,3 ] do
  key = headers[k];
  val = firstEntry[k]; 
  dataMap[key] = val;
end

key = headers[2];
dataMap[key] = indexMap;

for datum in noheaders do
  if (size(datum) > 4) do
    index = datum[2];
    priceType = datum[4];
    indexValMap = indexMap[index];
    if (indexValMap == null) do
      indexValMap = {};
      indexMap[index] = indexValMap;
    end
    priceTypeMap = indexValMap[priceType];
    if (priceTypeMap == null) do
      priceTypeMap = {};
      indexValMap[priceType] = priceTypeMap;  
    end
    datestr = datum[5];
    val = cast(datum[6], 'number');
    priceTypeMap[datestr] = val;
  end
end
#doc.putDoc(DOC_URI+"/introDataTranslated", json(dataMap));

println("Added JSON document to Rapture at " + DOC_URI+"/introDataTranslated"); 

println("\nDone\n");

// **********************
// Read the document as a JSON String. Convert the String to a Map
// then iterate through the map and recreate the lists.
// **********************

println("Read the document back and reconstitute the lists");

docStr = #doc.getDoc(DOC_URI+"/introDataTranslated");
docMap = fromjson(docStr);

csv = [ ] ;
indexes = docMap.index_id;
for i in keys(indexes) do
  index = indexes[i];
  for prices in keys(index) do
    priceMap = index[prices];
    for dateVal in keys(priceMap) do
      row = [];
      row.add(docMap.series_type);
      row.add(docMap.provider);
      row.add(i);
      row.add(docMap.frequency);
      row.add(prices);
      row.add(dateVal);
      row.add(priceMap[dateVal]);
      csv.add(row);
    end
  end
end

println("Adding price data from " + DOC_URI+"/introDataTranslated to series at " + SERIES_URI);

// add each date/price pair to the series, using the following template for the URI:
// seriesRepoUri + series_type + "/" + "provider" + "/" + "index_id" + "/" + "frequency" + "/" + "price_type"
// Since that is the order of the columns it's straightforward.
// Note that this can also be dome using the push operator: csv --> SERIES_URI;


for line in csv.subList(1, size(csv)) do
  location = SERIES_URI;
  columns = size(line);
  if (columns >= 2) do
     for field in line do
       if (columns == 1) do
         value = field;
       else if (columns == 2) do
         key = field;
       else do
         location = location+"/"+field;
       end
       columns = columns - 1;
     end
     #series.addDoubleToSeries(location, key, value);
   else do
     println("Line has less than 2 values: it will be skipped");
   end
end 
println("\nDone\n");
